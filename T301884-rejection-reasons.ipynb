{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ba45da",
   "metadata": {},
   "source": [
    "# Link Rejection Reasons\n",
    "\n",
    "The phab task for this work is [T301884](https://phabricator.wikimedia.org/T301884)\n",
    "\n",
    "To start with, we want to aggregate rejection reasons by wiki, platform, and user experience level in the form of the number of Add a Link edits they've made. We might later want to also split by whether they completed or skipped onboarding, but we'll not plan for that.\n",
    "\n",
    "We started out with a restriction on rejections within one week of registration. This turned out to provide us with little data on more experienced contributors. We therefore loosened the limit to within four weeks of registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7d77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from wmfdata import spark, mariadb\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7d3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll gather data from all of 2022 because we want to learn as much as possible,\n",
    "## and it's not essential that we right-truncate our data points. We will also have\n",
    "## to partition ServerSideAccountCreation manually, but that's reasonable.\n",
    "\n",
    "end_date = dt.date.today()\n",
    "start_date = dt.date(2022, 1, 1)\n",
    "\n",
    "## List of wikis that we're gathering data from:\n",
    "wikis = ['arwiki', 'bnwiki', 'cswiki', 'viwiki', 'fawiki',\n",
    "         'frwiki', 'huwiki', 'plwiki', 'rowiki', 'ruwiki',\n",
    "         'eswiki'] # deployed to eswiki on accident, so we'll analyze that too\n",
    "\n",
    "## Lists of known users to ignore (e.g. test accounts and experienced users)\n",
    "known_users = defaultdict(set)\n",
    "known_users['cswiki'].update([14, 127629, 303170, 342147, 349875, 44133, 100304, 307410, 439792, 444907,\n",
    "                              454862, 456272, 454003, 454846, 92295, 387915, 398470, 416764, 44751, 132801,\n",
    "                              137787, 138342, 268033, 275298, 317739, 320225, 328302, 339583, 341191,\n",
    "                              357559, 392634, 398626, 404765, 420805, 429109, 443890, 448195, 448438,\n",
    "                              453220, 453628, 453645, 453662, 453663, 453664, 440694, 427497, 272273,\n",
    "                              458025, 458487, 458049, 59563, 118067, 188859, 191908, 314640, 390445,\n",
    "                              451069, 459434, 460802, 460885, 79895, 448735, 453176, 467557, 467745,\n",
    "                              468502, 468583, 468603, 474052, 475184, 475185, 475187, 475188, 294174,\n",
    "                              402906, 298011])\n",
    "\n",
    "known_users['kowiki'].update([303170, 342147, 349875, 189097, 362732, 384066, 416362, 38759, 495265,\n",
    "                              515553, 537326, 566963, 567409, 416360, 414929, 470932, 472019, 485036,\n",
    "                              532123, 558423, 571587, 575553, 576758, 360703, 561281, 595100, 595105,\n",
    "                              595610, 596025, 596651, 596652, 596653, 596654, 596655, 596993, 942,\n",
    "                              13810, 536529])\n",
    "\n",
    "known_users['viwiki'].update([451842, 628512, 628513, 680081, 680083, 680084, 680085, 680086, 355424,\n",
    "                              387563, 443216, 682713, 659235, 700934, 705406, 707272, 707303, 707681, 585762])\n",
    "\n",
    "known_users['arwiki'].update([237660, 272774, 775023, 1175449, 1186377, 1506091, 1515147, 1538902,\n",
    "                              1568858, 1681813, 1683215, 1699418, 1699419, 1699425, 1740419, 1759328, 1763990])\n",
    "\n",
    "## Grab the user IDs of known test accounts so they can be added to the exclusion list\n",
    "\n",
    "def get_known_users(wiki):\n",
    "    '''\n",
    "    Get user IDs of known test accounts and return a set of them.\n",
    "    '''\n",
    "    \n",
    "    username_patterns = [\"MMiller\", \"Zilant\", \"Roan\", \"KHarlan\", \"MWang\", \"SBtest\",\n",
    "                         \"Cloud\", \"Rho2019\", \"Test\"]\n",
    "\n",
    "    known_user_query = '''\n",
    "SELECT user_id\n",
    "FROM user\n",
    "WHERE user_name LIKE \"{name_pattern}%\"\n",
    "    '''\n",
    "    \n",
    "    known_users = set()\n",
    "    \n",
    "    for u_pattern in username_patterns:\n",
    "        new_known = mariadb.run(known_user_query.format(\n",
    "            name_pattern = u_pattern), wiki)\n",
    "        known_users = known_users | set(new_known['user_id'])\n",
    "\n",
    "    return(known_users)\n",
    "        \n",
    "for wiki in wikis:\n",
    "    known_users[wiki] = known_users[wiki] | get_known_users(wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85309c48",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7080f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_known_users_sql(kd, wiki_column, user_column):\n",
    "    '''\n",
    "    Based on the dictionary `kd` mapping wiki names to sets of user IDs of known users,\n",
    "    create a SQL expression to exclude users based on the name of the wiki matching `wiki_column`\n",
    "    and the user ID not matching `user_column`\n",
    "    '''\n",
    "    \n",
    "    wiki_exp = '''({w_column} = '{wiki}' AND {u_column} NOT IN ({id_list}))'''\n",
    "    \n",
    "    expressions = list()\n",
    "\n",
    "    ## Iteratively build the expression for each wiki\n",
    "    for wiki_name, wiki_users in kd.items():\n",
    "        expressions.append(wiki_exp.format(\n",
    "            w_column = wiki_column,\n",
    "            wiki = wiki_name,\n",
    "            u_column = user_column,\n",
    "            id_list = ','.join([str(u) for u in wiki_users])\n",
    "        ))\n",
    "    \n",
    "    ## We then join all the expressions with an OR, and we're done.\n",
    "    return(' OR '.join(expressions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be087f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partition_statement(start_ts, end_ts, prefix = ''):\n",
    "    '''\n",
    "    This takes the two timestamps and creates a statement that selects\n",
    "    partitions based on `year`, `month`, and `day` in order to make our\n",
    "    data gathering not use excessive amounts of data. It assumes that\n",
    "    `start_ts` and `end_ts` are either in the same year, or if spanning\n",
    "    a year boundary are within a month apart.\n",
    "    This assumption simplifies the code and output a lot.\n",
    "    \n",
    "    An optional prefix can be set to enable selecting partitions for\n",
    "    multiple tables with different aliases.\n",
    "    \n",
    "    :param start_ts: start timestamp\n",
    "    :type start_ts: datetime.datetime\n",
    "    \n",
    "    :param end_ts: end timestamp\n",
    "    :type end_ts: datetime.datetime\n",
    "    \n",
    "    :param prefix: prefix to use in front of partition clauses, \".\" is added automatically\n",
    "    :type prefix: str\n",
    "    '''\n",
    "    \n",
    "    if prefix:\n",
    "        prefix = f'{prefix}.' # adds \".\" after the prefix\n",
    "    \n",
    "    # there are three cases:\n",
    "    # 1: month and year are the same, output a \"BETWEEN\" statement with the days\n",
    "    # 2: the years are the same, and the months differ by 1: output a statement for each month\n",
    "    # 3: the years are the same: create a list of statements from start_ts.month to end_ts.month,\n",
    "    #    return them OR'ed together\n",
    "    # 4: the years differ by 1, start_ts is December and end_ts is January, do the same as #2\n",
    "    # 5: anything else, raise an exception because this isn't implemented yet.\n",
    "    \n",
    "    if start_ts.year == end_ts.year and start_ts.month == end_ts.month:\n",
    "        return(f'''{prefix}year = {start_ts.year}\n",
    "AND {prefix}month = {start_ts.month}\n",
    "AND {prefix}day BETWEEN {start_ts.day} AND {end_ts.day}''')\n",
    "    elif start_ts.year == end_ts.year and (end_ts.month - start_ts.month) == 1:\n",
    "        return(f'''\n",
    "(\n",
    "    ({prefix}year = {start_ts.year}\n",
    "     AND {prefix}month = {start_ts.month}\n",
    "     AND {prefix}day >= {start_ts.day})\n",
    " OR ({prefix}year = {end_ts.year}\n",
    "     AND {prefix}month = {end_ts.month}\n",
    "     AND {prefix}day <= {end_ts.day})\n",
    ")''')\n",
    "    elif start_ts.year == end_ts.year:\n",
    "        # do the start month as a list\n",
    "        parts = [f'''({prefix}year = {start_ts.year}\n",
    "     AND {prefix}month = {start_ts.month}\n",
    "     AND {prefix}day >= {start_ts.day})''']\n",
    "        # for month +1 to end month, add each month\n",
    "        for m in range(start_ts.month+1, end_ts.month):\n",
    "            parts.append(f'''({prefix}year = {start_ts.year}\n",
    "            AND {prefix}month = {m})''')\n",
    "        # then append the end month and return a parenthesis OR'ed together of all of it\n",
    "        parts.append(f'''({prefix}year = {end_ts.year}\n",
    "     AND {prefix}month = {end_ts.month}\n",
    "     AND {prefix}day <= {end_ts.day})''')\n",
    "        return('({})'.format(\n",
    "            '\\nOR\\n'.join(parts)\n",
    "        ))\n",
    "    elif (end_ts.year - start_ts.year) == 1 and start_ts.month == 12 and end_ts.month == 1:\n",
    "        return(f'''\n",
    "(\n",
    "    ({prefix}year = {start_ts.year}\n",
    "     AND {prefix}month = {start_ts.month}\n",
    "     AND {prefix}day >= {start_ts.day})\n",
    " OR ({prefix}year = {end_ts.year}\n",
    "     AND {prefix}month = {end_ts.month}\n",
    "     AND {prefix}day <= {end_ts.day})\n",
    ")''')\n",
    "    else:\n",
    "        raise Exception('Difference between start and end timestamps is not implemented. See code for details.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26659c4",
   "metadata": {},
   "source": [
    "# Rejection Reason and Add a Link Edit query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e0f5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_query = '''\n",
    "WITH rejection_events AS (\n",
    "    SELECT\n",
    "        hpv.wiki,\n",
    "        hpv.event.user_id,\n",
    "        stimg.homepage_pageview_token,\n",
    "        stimg.is_mobile,\n",
    "        stimg.dt AS event_dt,\n",
    "        str_to_map(stimg.action_data, \";\", \"=\") AS action_data\n",
    "    FROM event.mediawiki_structured_task_article_link_suggestion_interaction AS stimg\n",
    "    JOIN event.homepagevisit AS hpv\n",
    "    ON stimg.homepage_pageview_token = hpv.event.homepage_pageview_token\n",
    "    WHERE {stimg_partition_statement}\n",
    "    AND {hpv_partition_statement}\n",
    "    AND hpv.wiki IN ({wiki_list})\n",
    "    AND ({hpv_known_user_id_expression})\n",
    "    AND stimg.active_interface = \"rejection_dialog\"\n",
    "    AND stimg.action = \"close\"\n",
    "    AND str_to_map(stimg.action_data, \";\", \"=\")[\"acceptance_state\"] = \"rejected\"\n",
    "    AND str_to_map(stimg.action_data, \";\", \"=\")[\"rejection_reason\"] != \"\"\n",
    "),\n",
    "registrations AS (\n",
    "    SELECT\n",
    "        wiki,\n",
    "        event.userid AS user_id,\n",
    "        dt AS reg_dt\n",
    "    FROM event.serversideaccountcreation\n",
    "    WHERE ((year = 2021 AND month = 12)\n",
    "           OR year = 2022)\n",
    "    AND wiki IN ({wiki_list})\n",
    "    AND ({known_userid_expression})\n",
    "),\n",
    "rejection_reasons AS (\n",
    "    SELECT\n",
    "        rej.*,\n",
    "        reg.reg_dt,\n",
    "        EXPLODE(SPLIT(rej.action_data[\"rejection_reason\"], \",\")) AS rejection_reason\n",
    "    FROM rejection_events AS rej\n",
    "    JOIN registrations AS reg\n",
    "    ON rej.wiki = reg.wiki\n",
    "    AND rej.user_id = reg.user_id\n",
    "    -- only rejections within four weeks of registration\n",
    "    WHERE (unix_timestamp(rej.event_dt, \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\") -\n",
    "            unix_timestamp(reg.reg_dt, \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\") < 60*60*24*28)\n",
    "),\n",
    "edit_revert AS (\n",
    "    -- edits tagged with Add a Link (wiki, user_id, page_id, timestamp)\n",
    "    -- whether the edit was reverted within 48 hours\n",
    "    SELECT\n",
    "        `database` AS wiki,\n",
    "        rev_id,\n",
    "        FIRST_VALUE(page_id) AS page_id,\n",
    "        FIRST_VALUE(performer.user_id) AS user_id,\n",
    "        FIRST_VALUE(performer.user_registration_dt) AS user_registration_dt,\n",
    "        FIRST_VALUE(rev_timestamp) AS rev_timestamp,\n",
    "        MAX(IF(array_contains(tags, 'mw-reverted') AND\n",
    "               (unix_timestamp(meta.dt, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") -\n",
    "                unix_timestamp(rev_timestamp, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") < 60*60*48), 1, 0)) AS was_reverted\n",
    "    FROM event_sanitized.mediawiki_revision_tags_change\n",
    "    WHERE {partition_statement}\n",
    "    AND `database` IN ({wiki_list})\n",
    "    AND ({known_user_database_expression})\n",
    "    AND array_contains(tags, \"newcomer task add link\")\n",
    "    -- Only counting edits made within one week of registration\n",
    "    AND (unix_timestamp(rev_timestamp, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") -\n",
    "                unix_timestamp(performer.user_registration_dt, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") < 60*60*24*28)\n",
    "    GROUP BY wiki, rev_id\n",
    "),\n",
    "user_edit_count AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        row_number() OVER (PARTITION BY wiki, user_id ORDER BY rev_timestamp) AS edit_number\n",
    "    FROM edit_revert\n",
    ")\n",
    "SELECT\n",
    "    rej.homepage_pageview_token,\n",
    "    rej.wiki,\n",
    "    rej.user_id,\n",
    "    rej.is_mobile,\n",
    "    rej.event_dt,\n",
    "    rej.reg_dt,\n",
    "    rej.rejection_reason,\n",
    "    COALESCE(\n",
    "        MAX(\n",
    "            IF(unix_timestamp(rev_timestamp, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") <\n",
    "                   unix_timestamp(rej.event_dt, \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\"),\n",
    "                edit_number, NULL)\n",
    "        ), 0) AS tagged_edit_count\n",
    "FROM rejection_reasons AS rej\n",
    "LEFT JOIN user_edit_count AS edits\n",
    "ON rej.wiki = edits.wiki\n",
    "AND rej.user_id = edits.user_id\n",
    "GROUP BY rej.homepage_pageview_token, rej.wiki, rej.user_id, rej.is_mobile,\n",
    "         rej.event_dt, rej.reg_dt, rej.rejection_reason\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f9348b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "rejection_data = spark.run(\n",
    "    rejection_query.format(\n",
    "        wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis]),\n",
    "        known_user_database_expression = make_known_users_sql(known_users,\n",
    "                                                              '`database`', 'performer.user_id'),\n",
    "        known_user_id_expression = make_known_users_sql(known_users, 'wiki', 'event.user_id'),\n",
    "        known_userid_expression = make_known_users_sql(known_users, 'wiki', 'event.userid'),\n",
    "        hpv_known_user_id_expression = make_known_users_sql(known_users, 'wiki', 'hpv.event.user_id'),\n",
    "        partition_statement = make_partition_statement(start_date, end_date),\n",
    "        hpv_partition_statement = make_partition_statement(start_date, end_date, prefix = 'hpv'),\n",
    "        stimg_partition_statement = make_partition_statement(start_date, end_date, prefix = 'stimg'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68819b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8598"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rejection_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f357e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "087d5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_data.to_csv('datasets/rejection-reasons-2022-03-04.csv', index = False,\n",
    "                     columns = ['wiki', 'is_mobile', 'rejection_reason', 'tagged_edit_count'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
