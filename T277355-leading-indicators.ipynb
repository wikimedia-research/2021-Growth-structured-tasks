{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9099fcba",
   "metadata": {},
   "source": [
    "# Add a Link: Leading Indicators\n",
    "\n",
    "The phab task for this is [T277355](https://phabricator.wikimedia.org/T277355)\n",
    "\n",
    "We've got the following four leading indicators:\n",
    "\n",
    "1. Revert rate: compare Add a Link edits to that of unstructured link tasks.\n",
    "2. User rejection rate: do users reject more than 30% of links?\n",
    "3. Task completion rate: what is the proportion of users who start the Add a Link task and complete it? If it is below 75%, we investigate.\n",
    "\n",
    "With regards to rejection rate, we also want to calculate \"proportion of users who accept all links\". We then want to compare the rejection rate when exluding these users from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f083c70",
   "metadata": {},
   "source": [
    "# Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3752539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from wmfdata import spark, mariadb\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0eaa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start timestamp of the experiment (https://phabricator.wikimedia.org/T277356#7120922)\n",
    "exp_start = '2021-05-27T19:12:03'\n",
    "\n",
    "exp_start_ts = dt.datetime.strptime(exp_start, '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "## We'll limit data gathering to midnight June 14, the day we're gathering data\n",
    "exp_end_ts = dt.datetime(2021, 6, 14, 0, 0, 0)\n",
    "\n",
    "## List of wikis that we deployed to:\n",
    "wikis = ['arwiki','bnwiki','cswiki', 'viwiki']\n",
    "\n",
    "## Lists of known users to ignore (e.g. test accounts and experienced users)\n",
    "known_users = defaultdict(set)\n",
    "known_users['cswiki'].update([14, 127629, 303170, 342147, 349875, 44133, 100304, 307410, 439792, 444907,\n",
    "                              454862, 456272, 454003, 454846, 92295, 387915, 398470, 416764, 44751, 132801,\n",
    "                              137787, 138342, 268033, 275298, 317739, 320225, 328302, 339583, 341191,\n",
    "                              357559, 392634, 398626, 404765, 420805, 429109, 443890, 448195, 448438,\n",
    "                              453220, 453628, 453645, 453662, 453663, 453664, 440694, 427497, 272273,\n",
    "                              458025, 458487, 458049, 59563, 118067, 188859, 191908, 314640, 390445,\n",
    "                              451069, 459434, 460802, 460885, 79895, 448735, 453176, 467557, 467745,\n",
    "                              468502, 468583, 468603, 474052, 475184, 475185, 475187, 475188, 294174,\n",
    "                              402906, 298011])\n",
    "\n",
    "known_users['kowiki'].update([303170, 342147, 349875, 189097, 362732, 384066, 416362, 38759, 495265,\n",
    "                              515553, 537326, 566963, 567409, 416360, 414929, 470932, 472019, 485036,\n",
    "                              532123, 558423, 571587, 575553, 576758, 360703, 561281, 595100, 595105,\n",
    "                              595610, 596025, 596651, 596652, 596653, 596654, 596655, 596993, 942,\n",
    "                              13810, 536529])\n",
    "\n",
    "known_users['viwiki'].update([451842, 628512, 628513, 680081, 680083, 680084, 680085, 680086, 355424,\n",
    "                              387563, 443216, 682713, 659235, 700934, 705406, 707272, 707303, 707681, 585762])\n",
    "\n",
    "known_users['arwiki'].update([237660, 272774, 775023, 1175449, 1186377, 1506091, 1515147, 1538902,\n",
    "                              1568858, 1681813, 1683215, 1699418, 1699419, 1699425, 1740419, 1759328, 1763990])\n",
    "\n",
    "## Grab the user IDs of known test accounts so they can be added to the exclusion list\n",
    "\n",
    "def get_known_users(wiki):\n",
    "    '''\n",
    "    Get user IDs of known test accounts and return a set of them.\n",
    "    '''\n",
    "    \n",
    "    username_patterns = [\"MMiller\", \"Zilant\", \"Roan\", \"KHarlan\", \"MWang\", \"SBtest\",\n",
    "                         \"Cloud\", \"Rho2019\", \"Test\"]\n",
    "\n",
    "    known_user_query = '''\n",
    "SELECT user_id\n",
    "FROM user\n",
    "WHERE user_name LIKE \"{name_pattern}%\"\n",
    "    '''\n",
    "    \n",
    "    known_users = set()\n",
    "    \n",
    "    for u_pattern in username_patterns:\n",
    "        new_known = mariadb.run(known_user_query.format(\n",
    "            name_pattern = u_pattern), wiki)\n",
    "        known_users = known_users | set(new_known['user_id'])\n",
    "\n",
    "    return(known_users)\n",
    "        \n",
    "for wiki in wikis:\n",
    "    known_users[wiki] = known_users[wiki] | get_known_users(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f46311",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Controlling the maximum number of rows, columns, and output width used\n",
    "## by Pandas. Update it with larger values if tables start getting truncated.\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06ab8a",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8edc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_known_users_sql(kd, wiki_column, user_column):\n",
    "    '''\n",
    "    Based on the dictionary `kd` mapping wiki names to sets of user IDs of known users,\n",
    "    create a SQL expression to exclude users based on the name of the wiki matching `wiki_column`\n",
    "    and the user ID not matching `user_column`\n",
    "    '''\n",
    "    \n",
    "    wiki_exp = '''({w_column} = '{wiki}' AND {u_column} NOT IN ({id_list}))'''\n",
    "    \n",
    "    expressions = list()\n",
    "\n",
    "    ## Iteratively build the expression for each wiki\n",
    "    for wiki_name, wiki_users in kd.items():\n",
    "        expressions.append(wiki_exp.format(\n",
    "            w_column = wiki_column,\n",
    "            wiki = wiki_name,\n",
    "            u_column = user_column,\n",
    "            id_list = ','.join([str(u) for u in wiki_users])\n",
    "        ))\n",
    "    \n",
    "    ## We then join all the expressions with an OR, and we're done.\n",
    "    return(' OR '.join(expressions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24075097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_when_then(wiki_list, wiki_column):\n",
    "    '''\n",
    "    Take the ordered list of wiki names and turn it into a string\n",
    "    of \"WHEN wiki_column = '{wiki}' THEN '{k}'\" where `k` is the index\n",
    "    of the wiki in the list, so it can be used for ordering results.\n",
    "    '''\n",
    "\n",
    "    whens = list()\n",
    "    \n",
    "    for k, wiki in enumerate(wiki_list):\n",
    "        whens.append(f'WHEN {wiki_column} = \"{wiki}\" THEN \"{k:02}\"')\n",
    "    \n",
    "    ## Join them with line breaks to create the list\n",
    "    return('\\n'.join(whens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1bac4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partition_statement(start_ts, end_ts, prefix = ''):\n",
    "    '''\n",
    "    This takes the two timestamps and creates a statement that selects\n",
    "    partitions based on `year`, `month`, and `day` in order to make our\n",
    "    data gathering not use excessive amounts of data. It assumes that\n",
    "    `start_ts` and `end_ts` are not more than a month apart.\n",
    "    This assumption simplifies the code and output a lot.\n",
    "    \n",
    "    An optional prefix can be set to enable selecting partitions for\n",
    "    multiple tables with different aliases.\n",
    "    \n",
    "    :param start_ts: start timestamp\n",
    "    :type start_ts: datetime.datetime\n",
    "    \n",
    "    :param end_ts: end timestamp\n",
    "    :type end_ts: datetime.datetime\n",
    "    \n",
    "    :param prefix: prefix to use in front of partition clauses, \".\" is added automatically\n",
    "    :type prefix: str\n",
    "    '''\n",
    "    \n",
    "    if prefix:\n",
    "        prefix = f'{prefix}.' # adds \".\" after the prefix\n",
    "    \n",
    "    # there are three cases:\n",
    "    # 1: month and year are the same, output a \"BETWEEN\" statement with the days\n",
    "    # 2: months differ, but the years the same.\n",
    "    # 3: years differ too.\n",
    "    # Case #2 and #3 can be combined, because it doesn't really matter\n",
    "    # if the years are the same in the month-selection or not.\n",
    "    \n",
    "    if start_ts.year == end_ts.year and start_ts.month == end_ts.month:\n",
    "        return(f'''{prefix}year = {start_ts.year}\n",
    "AND {prefix}month = {start_ts.month}\n",
    "AND {prefix}day BETWEEN {start_ts.day} AND {end_ts.day}''')\n",
    "    else:\n",
    "        return(f'''\n",
    "(\n",
    "    ({prefix}year = {start_ts.year}\n",
    "     AND {prefix}month = {start_ts.month}\n",
    "     AND {prefix}day >= {start_ts.day})\n",
    " OR ({prefix}year = {end_ts.year}\n",
    "     AND {prefix}month = {end_ts.month}\n",
    "     AND {prefix}day <= {end_ts.day})\n",
    ")''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17fb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_cell(x, num_decimals = 1):\n",
    "    '''\n",
    "    Try converting the value of `x` into a float, then rounding to the specified\n",
    "    number of decimal places. Used when outputting `pandas.DataFrame` that contain\n",
    "    columns full of `object` data types. If the value cannot be parsed as a float,\n",
    "    the value is returned as-is.\n",
    "    \n",
    "    :param x: whatever we want to try to round\n",
    "    :type x: obj\n",
    "    \n",
    "    :param num_decimals: the number of decimal places to round to\n",
    "    :type num_decimals: int\n",
    "    '''\n",
    "    try:\n",
    "        return(round(float(x), num_decimals))\n",
    "    except ValueError:\n",
    "        return(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca6a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_sort_wiki_df(wiki_list, df, name_column = 'wiki', value_column = None):\n",
    "    '''\n",
    "    Takes the given list of wikis and compares them with the named column\n",
    "    in the dataframe.\n",
    "    \n",
    "    If no value column is defined, it adds one empty row to the dataframe\n",
    "    for each missing wiki.\n",
    "    \n",
    "    If a value column is defined, it identifies the unique values in that column\n",
    "    and adds them for each wiki.\n",
    "    \n",
    "    Once the full new dataframe is completed, all NAs are replaced with 0,\n",
    "    and the dataframe is sorted by the name and value columns.\n",
    "    \n",
    "    :param wiki_list: list of all the wikis we're expecting to have data for\n",
    "    :type wiki_list: list\n",
    "    \n",
    "    :param df: dataframe with data, possibly missing some wikis.\n",
    "    :type df: pandas.DataFrame\n",
    "    \n",
    "    :param name_column: column in the dataframe that contains wiki names\n",
    "    :type name_column: str\n",
    "    \n",
    "    :param value_column: name of a column that holds values we should generate rows for.\n",
    "    :type value_column: str\n",
    "    '''\n",
    "\n",
    "    ## We name a series out of the list of wikis, then use that to create a dataframe\n",
    "    ## containing the name of any wiki not already in the named column. Then we set\n",
    "    ## all the values to 0, and sort the resulting dataframe by the named column.\n",
    "\n",
    "    wikis_s = pd.Series(wiki_list)\n",
    "    \n",
    "    if value_column is None:\n",
    "        return(\n",
    "            pd.concat([\n",
    "                df,\n",
    "                pd.DataFrame({name_column : wikis_s.loc[~wikis_s.isin(df[name_column])]})\n",
    "            ]).fillna(0).sort_values(name_column))\n",
    "    else:\n",
    "        # Identify what wikis we're missing, and if we're not missing any just return\n",
    "        # the existing dataframe\n",
    "        missing_wikis = wikis_s.loc[~wikis_s.isin(df[name_column])]\n",
    "        if missing_wikis.empty:\n",
    "            return(df)\n",
    "        \n",
    "        ## From https://stackoverflow.com/a/26977495\n",
    "        unique_values = pd.unique(df[value_column])\n",
    "\n",
    "        new_df = pd.concat([\n",
    "            df,\n",
    "            pd.concat( # combine the results of the list comprehension\n",
    "                [\n",
    "                    pd.DataFrame( # for each element in the list, create a pandas.DataFrame\n",
    "                        {name_column : [w] * len(unique_values), # repeat the wiki name to match the values\n",
    "                         value_column : unique_values}) # add all the unique values of the value column\n",
    "                    for w in wikis_s.loc[~wikis_s.isin(df[name_column])] # do this for every missing wiki\n",
    "                ]\n",
    "            )\n",
    "        ])\n",
    "        return(new_df.fillna(0).sort_values([name_column, value_column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b13eb8",
   "metadata": {},
   "source": [
    "# Revert Rate\n",
    "\n",
    "The way we've done this previously is to only look at user activity within 24 hours of registration, because that's when most of the visits to the Newcomer Homepage take place. In this case, we want to identify all users who visited the Homepage, clicked on either an Add a Link or unstructured link task, and saved an edit to that page. We'll then want to look at the revert rate, both overall on average per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0f84e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_query = '''\n",
    "WITH hp_visits AS (\n",
    "    SELECT\n",
    "        hpv.wiki,\n",
    "        hpv.event.user_id,\n",
    "        hpv.event.homepage_pageview_token,\n",
    "        hpv.dt AS event_dt\n",
    "    FROM event.homepagevisit AS hpv\n",
    "    WHERE {partition_statement}\n",
    "    AND wiki IN ({wiki_list})\n",
    "    AND ({known_user_id_expression})\n",
    "    AND dt >= \"{start_ts}\" AND dt < \"{end_ts}\"\n",
    "),\n",
    "newcomer_tasks AS (\n",
    "-- grab unique task token/task type data from newcomer tasks\n",
    "    SELECT\n",
    "        DISTINCT event.newcomer_task_token, event.task_type, event.page_id\n",
    "    FROM event.newcomertask\n",
    "    WHERE {partition_statement}\n",
    "    AND event.task_type IN (\"links\", \"link-recommendation\")\n",
    "),\n",
    "homepage_task_clicks AS (\n",
    "    -- clicks to tasks in sessions found in hp_visits\n",
    "    SELECT\n",
    "        hpm.wiki,\n",
    "        hpm.event.user_id,\n",
    "        hpm.dt AS event_dt,\n",
    "        str_to_map(hpm.event.action_data, \";\", \"=\") AS action_data\n",
    "    FROM event.homepagemodule AS hpm\n",
    "    JOIN hp_visits\n",
    "    ON hpm.event.homepage_pageview_token = hp_visits.homepage_pageview_token\n",
    "    WHERE {partition_statement}\n",
    "    AND event.action = \"se-task-click\"\n",
    "    AND dt >= \"{start_ts}\" AND dt < \"{end_ts}\"\n",
    "    AND dt > hp_visits.event_dt\n",
    "),\n",
    "postedit_task_clicks AS (\n",
    "    -- clicks to tasks done after saving an edit\n",
    "    SELECT\n",
    "        hp.wiki,\n",
    "        hp.event.user_id,\n",
    "        hp.dt AS event_dt,\n",
    "        str_to_map(hp.event.action_data, \";\", \"=\") AS action_data\n",
    "    FROM event.helppanel AS hp\n",
    "    WHERE {partition_statement}\n",
    "    AND wiki IN ({wiki_list})\n",
    "    AND ({known_user_id_expression})\n",
    "    AND event.action = \"postedit-task-click\"\n",
    "    AND dt >= \"{start_ts}\" AND dt < \"{end_ts}\"\n",
    "\n",
    "),\n",
    "link_task_clicks AS (\n",
    "-- filter task_clicks down to those on links and link recommendations\n",
    "    SELECT\n",
    "        task_clicks.wiki,\n",
    "        task_clicks.user_id,\n",
    "        task_clicks.event_dt,\n",
    "        newcomer_tasks.page_id,\n",
    "        newcomer_tasks.task_type,\n",
    "        LEAD(task_clicks.event_dt, 1) OVER\n",
    "            (PARTITION BY task_clicks.wiki, task_clicks.user_id, newcomer_tasks.page_id\n",
    "             ORDER BY task_clicks.event_dt) AS next_click_dt\n",
    "    FROM (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM homepage_task_clicks\n",
    "        UNION ALL\n",
    "        SELECT\n",
    "            *\n",
    "        FROM postedit_task_clicks) AS task_clicks\n",
    "    JOIN newcomer_tasks\n",
    "    ON task_clicks.action_data[\"newcomerTaskToken\"] = newcomer_tasks.newcomer_task_token\n",
    "),\n",
    "edits AS (\n",
    "-- edits and reverts (within 48 hours) of newcomer tasks\n",
    "    SELECT\n",
    "        `database` AS wiki,\n",
    "        rev_id,\n",
    "        FIRST_VALUE(page_id) AS page_id,\n",
    "        FIRST_VALUE(performer.user_id) AS user_id,\n",
    "        FIRST_VALUE(rev_timestamp) AS rev_timestamp,\n",
    "        MAX(IF(array_contains(tags, 'mw-reverted') AND\n",
    "               (unix_timestamp(meta.dt, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") -\n",
    "                unix_timestamp(rev_timestamp, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") < 60*60*48), 1, 0)) AS was_reverted\n",
    "    FROM event_sanitized.mediawiki_revision_tags_change\n",
    "    WHERE {partition_statement}\n",
    "    AND `database` IN ({wiki_list})\n",
    "    AND ({known_user_database_expression})\n",
    "    AND array_contains(tags, \"newcomer task\")\n",
    "    GROUP BY wiki, rev_id\n",
    ")\n",
    "SELECT\n",
    "    link_task_clicks.wiki,\n",
    "    link_task_clicks.user_id,\n",
    "    link_task_clicks.task_type,\n",
    "    COUNT(1) AS num_edits,\n",
    "    SUM(edits.was_reverted) AS num_reverts\n",
    "FROM link_task_clicks\n",
    "JOIN edits\n",
    "ON link_task_clicks.wiki = edits.wiki\n",
    "AND link_task_clicks.user_id = edits.user_id\n",
    "AND link_task_clicks.page_id = edits.page_id\n",
    "WHERE (link_task_clicks.next_click_dt IS NULL\n",
    "       OR link_task_clicks.event_dt != link_task_clicks.next_click_dt) -- removing duplicates\n",
    "AND edits.rev_timestamp > link_task_clicks.event_dt\n",
    "AND (\n",
    "        (link_task_clicks.next_click_dt IS NOT NULL\n",
    "         AND unix_timestamp(edits.rev_timestamp, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") <\n",
    "             unix_timestamp(link_task_clicks.next_click_dt, \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\"))\n",
    "    OR\n",
    "        (unix_timestamp(edits.rev_timestamp, \"yyyy-MM-dd'T'HH:mm:ss'Z'\") -\n",
    "         unix_timestamp(link_task_clicks.event_dt, \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\") < 60*60*24*7)\n",
    "    )\n",
    "GROUP BY link_task_clicks.wiki, link_task_clicks.user_id, link_task_clicks.task_type\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066c98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "link_task_edits_data = spark.run(\n",
    "    revert_query.format(\n",
    "        start_ts = exp_start_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        end_ts = exp_end_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis]),\n",
    "        known_user_id_expression = make_known_users_sql(known_users, 'wiki', 'event.user_id'),\n",
    "        known_userid_expression = make_known_users_sql(known_users, 'wiki', 'event.userid'),\n",
    "        known_user_database_expression = make_known_users_sql(known_users,\n",
    "                                                              '`database`', 'performer.user_id'),\n",
    "        partition_statement = make_partition_statement(exp_start_ts, exp_end_ts)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_task_edits_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc917d1e",
   "metadata": {},
   "source": [
    "Number of task edits, reverts, and revert rate in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c96c351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_reverts</th>\n",
       "      <th>revert_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>link-recommendation</th>\n",
       "      <td>1248</td>\n",
       "      <td>77</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>88</td>\n",
       "      <td>23</td>\n",
       "      <td>26.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     num_edits  num_reverts  revert_rate\n",
       "task_type                                               \n",
       "link-recommendation       1248           77          6.2\n",
       "links                       88           23         26.1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_tasks_agg = link_task_edits_data.groupby('task_type').agg({'num_edits' : 'sum', 'num_reverts' : 'sum'})\n",
    "link_tasks_agg['revert_rate'] = 100 * link_tasks_agg['num_reverts'] / link_tasks_agg['num_edits']\n",
    "link_tasks_agg.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_task_edits_data.sort_values('num_edits', ascending = False).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04336907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.87686979941189,\n",
       " 9.818454907000372e-09,\n",
       " 1,\n",
       " array([[1232.72980501,   92.27019499],\n",
       "        [ 103.27019499,    7.72980501]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(link_tasks_agg[['num_edits', 'num_reverts']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868aae9",
   "metadata": {},
   "source": [
    "## Overall statistics\n",
    "\n",
    "For the slide deck, for each wiki, aggregate the number of edits and editors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef99fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_reverts</th>\n",
       "      <th>num_editors</th>\n",
       "      <th>revert_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki</th>\n",
       "      <th>task_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">arwiki</th>\n",
       "      <th>link-recommendation</th>\n",
       "      <td>884</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bnwiki</th>\n",
       "      <th>link-recommendation</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cswiki</th>\n",
       "      <th>link-recommendation</th>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">viwiki</th>\n",
       "      <th>link-recommendation</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            num_edits  num_reverts  num_editors  revert_rate\n",
       "wiki   task_type                                                            \n",
       "arwiki link-recommendation        884           71           94          8.0\n",
       "       links                       51           13           17         25.5\n",
       "bnwiki link-recommendation         83            2           18          2.4\n",
       "       links                       10            1            6         10.0\n",
       "cswiki link-recommendation        206            3           22          1.5\n",
       "       links                        7            1            5         14.3\n",
       "viwiki link-recommendation         75            1           24          1.3\n",
       "       links                       20            8            8         40.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_agg = (link_task_edits_data.groupby(['wiki', 'task_type'])\n",
    "               .agg({'num_edits' : 'sum', 'num_reverts' : 'sum', 'user_id' : 'count'})\n",
    "               .rename(columns = {'user_id' : 'num_editors'}))\n",
    "overall_agg['revert_rate'] = 100 * overall_agg['num_reverts'] / overall_agg['num_edits']\n",
    "overall_agg.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57288cf2",
   "metadata": {},
   "source": [
    "# Rejection Rate\n",
    "\n",
    "Q: Do we count all rejections, or only those that are part of saved edits? Do we count all edit sessions, or only those made by new accounts?\n",
    "\n",
    "A: We'll count edit sessions from all users, because in this case experienced users are going to be better able to determine if a suggested link is appropriate. We will, however, only count saved edits, because we want to ignore users loading up the editor and testing out Add a Link.\n",
    "\n",
    "To make things easier, we'll use the structured task schema as our source of data because it has an `editsummary_save` event. Since we're relying on instrumented events, that's going to make it easier.\n",
    "\n",
    "Also, the number of accepted, rejected, and skipped links is also saved in the edit summary of each edit. That data is, however, localized to each wiki so I'm not going to spend time digging those numbers out.\n",
    "\n",
    "### Notes\n",
    "\n",
    "There is the possibility that a user gets to the edit summary screen and then choses to go back and make changes. We'll treat this as two separate end states and count both. We do this because we expect the number of times this happens to be relatively low, and secondly that there isn't anything wrong with going back and changing your mind.\n",
    "\n",
    "For the `skipall_dialog`, we'll need to go fetch their initial impression of the interface, because that's where the number of suggestions is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d01beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_rate_query = '''\n",
    "WITH saved_edits AS (\n",
    "    SELECT\n",
    "        coalesce(lsi.dt, lsi.meta.dt) AS event_dt,\n",
    "        lsi.homepage_pageview_token,\n",
    "        hpv.wiki,\n",
    "        hpv.event.user_id\n",
    "    FROM event.mediawiki_structured_task_article_link_suggestion_interaction AS lsi\n",
    "    JOIN event.homepagevisit AS hpv\n",
    "    ON lsi.homepage_pageview_token = hpv.event.homepage_pageview_token\n",
    "    WHERE {lsi_partition_statement}\n",
    "    AND {hpv_partition_statement}\n",
    "    AND hpv.wiki IN ({wiki_list})\n",
    "    AND ({known_user_id_expression})\n",
    "    AND lsi.action = \"editsummary_save\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) >= \"{start_ts}\" AND coalesce(lsi.dt, lsi.meta.dt) < \"{end_ts}\"\n",
    "),\n",
    "saved_rates AS ( -- grab accept/reject/skips for saved edits\n",
    "    -- str_to_map() first splits on \";\" (the pair delimiter),\n",
    "    -- then splits each key/value pair on \"=\" (the key/value delimiter)\n",
    "    SELECT\n",
    "        lsi.homepage_pageview_token,\n",
    "        saved_edits.user_id,\n",
    "        saved_edits.wiki,\n",
    "        coalesce(lsi.dt, lsi.meta.dt) as event_dt,\n",
    "        str_to_map(lsi.action_data, \";\", \"=\") AS rate_map\n",
    "    FROM saved_edits\n",
    "    JOIN event.mediawiki_structured_task_article_link_suggestion_interaction AS lsi\n",
    "    ON saved_edits.homepage_pageview_token = lsi.homepage_pageview_token\n",
    "    WHERE {lsi_partition_statement}\n",
    "    AND lsi.action = \"impression\"\n",
    "    AND lsi.active_interface = \"editsummary_dialog\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) >= \"{start_ts}\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) < \"{end_ts}\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) < saved_edits.event_dt\n",
    "),\n",
    "skip_alls AS (\n",
    "    SELECT\n",
    "        coalesce(lsi.dt, lsi.meta.dt) AS event_dt,\n",
    "        lsi.homepage_pageview_token,\n",
    "        hpv.wiki,\n",
    "        hpv.event.user_id\n",
    "    FROM event.mediawiki_structured_task_article_link_suggestion_interaction AS lsi\n",
    "    JOIN event.homepagevisit AS hpv\n",
    "    ON lsi.homepage_pageview_token = hpv.event.homepage_pageview_token\n",
    "    WHERE {lsi_partition_statement}\n",
    "    AND {hpv_partition_statement}\n",
    "    AND hpv.wiki IN ({wiki_list})\n",
    "    AND ({known_user_id_expression})\n",
    "    AND lsi.active_interface = \"skipall_dialog\"\n",
    "    AND lsi.action = \"confirm_skip_all_suggestions\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) >= \"{start_ts}\" AND coalesce(lsi.dt, lsi.meta.dt) < \"{end_ts}\"\n",
    "),\n",
    "skip_all_rates AS ( -- grab the suggestion count from start of the sessions\n",
    "    SELECT\n",
    "        lsi.homepage_pageview_token,\n",
    "        skip_alls.user_id,\n",
    "        skip_alls.wiki,\n",
    "        coalesce(lsi.dt, lsi.meta.dt) as event_dt,\n",
    "        -- building a map similar to what we have for saved edits\n",
    "        map(\"accepted_count\", \"0\", \"rejected_count\", \"0\",\n",
    "            \"skipped_count\",\n",
    "            str_to_map(lsi.action_data, \";\", \"=\")[\"number_phrases_found\"]) AS rate_map\n",
    "    FROM skip_alls\n",
    "    JOIN event.mediawiki_structured_task_article_link_suggestion_interaction AS lsi\n",
    "    ON skip_alls.homepage_pageview_token = lsi.homepage_pageview_token\n",
    "    WHERE {lsi_partition_statement}\n",
    "    AND lsi.action = \"impression\"\n",
    "    AND lsi.active_interface = \"machinesuggestions_mode\"\n",
    "    AND lsi.action = \"impression\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) >= \"{start_ts}\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) < \"{end_ts}\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) < skip_alls.event_dt\n",
    "),\n",
    "rates_cast AS (\n",
    "    SELECT\n",
    "        wiki,\n",
    "        user_id,\n",
    "        homepage_pageview_token,\n",
    "        CAST(rate_map['accepted_count'] AS INT) AS accepted_count,\n",
    "        CAST(rate_map['rejected_count'] AS INT) AS rejected_count,\n",
    "        CAST(rate_map['skipped_count'] AS INT) AS skipped_count\n",
    "    FROM\n",
    "        (SELECT\n",
    "             *\n",
    "         FROM saved_rates\n",
    "         UNION ALL\n",
    "         SELECT\n",
    "             *\n",
    "         FROM skip_all_rates) AS r\n",
    ")\n",
    "SELECT\n",
    "    wiki,\n",
    "    user_id,\n",
    "    SUM(accepted_count) AS num_links_accepted,\n",
    "    SUM(rejected_count) AS num_links_rejected,\n",
    "    SUM(skipped_count) AS num_links_skipped,\n",
    "    SUM(accepted_count + rejected_count + skipped_count) AS num_links_recommended,\n",
    "    COUNT(1) AS num_edit_sessions,\n",
    "    COUNT(IF(accepted_count = accepted_count + rejected_count + skipped_count, 1, NULL)) AS num_all_accepted,\n",
    "    COUNT(IF(rejected_count = accepted_count + rejected_count + skipped_count, 1, NULL)) AS num_all_rejected,\n",
    "    COUNT(IF(skipped_count = accepted_count + rejected_count + skipped_count, 1, NULL)) AS num_all_skipped\n",
    "FROM rates_cast\n",
    "GROUP BY wiki, user_id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4633eb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "rate_data = spark.run(\n",
    "    rejection_rate_query.format(\n",
    "        start_ts = exp_start_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        end_ts = exp_end_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis]),\n",
    "        known_user_id_expression = make_known_users_sql(known_users, 'wiki', 'hpv.event.user_id'),\n",
    "        lsi_partition_statement = make_partition_statement(exp_start_ts, exp_end_ts, prefix = 'lsi'),\n",
    "        hpv_partition_statement = make_partition_statement(exp_start_ts, exp_end_ts, prefix = 'hpv')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_data.loc[rate_data['wiki'] == 'arwiki'].sort_values('num_edit_sessions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9be8d",
   "metadata": {},
   "source": [
    "Now we can easily calculate the overall acceptance, rejection, and skip rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9120210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_data['num_links_accepted'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d118b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 * rate_data['num_links_accepted'].sum() / rate_data['num_links_recommended'].sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6e7a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_data['num_links_rejected'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bde6bb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 * rate_data['num_links_rejected'].sum() / rate_data['num_links_recommended'].sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f4bad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_data['num_links_skipped'].sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0183e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 * rate_data['num_links_skipped'].sum() / rate_data['num_links_recommended'].sum(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346dbf2",
   "metadata": {},
   "source": [
    "Using this data, we can also calculate whether a user accepts all links or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96db5a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08a52ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f81b5551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "     len(rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted']]) /\n",
    "     len(rate_data), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa6bbe1",
   "metadata": {},
   "source": [
    "So about 27% of users have only edit sessions where they've accepted all the recommended links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d926bd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'num_edit_sessions'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1028fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_data['num_edit_sessions'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c8a88b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "     rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'num_edit_sessions'].sum() /\n",
    "     rate_data['num_edit_sessions'].sum(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc48e0c",
   "metadata": {},
   "source": [
    "These users are not very active, as their edit sessions only make up 8.8% of the total sessions.\n",
    "\n",
    "If we remove the users from the accept/reject/skip proportions, the new values become as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0cd516c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "    rate_data.loc[\n",
    "        ~rate_data['user_id'].isin(\n",
    "            rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'user_id']),\n",
    "    'num_links_accepted'].sum() /\n",
    "    rate_data.loc[\n",
    "        ~rate_data['user_id'].isin(\n",
    "            rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'user_id']),\n",
    "    'num_links_recommended'].sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dbdc139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "    rate_data.loc[\n",
    "        ~rate_data['user_id'].isin(\n",
    "            rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'user_id']),\n",
    "    'num_links_rejected'].sum() /\n",
    "    rate_data.loc[\n",
    "        ~rate_data['user_id'].isin(\n",
    "            rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'user_id']),\n",
    "    'num_links_recommended'].sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "181a00a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "    rate_data.loc[\n",
    "        ~rate_data['user_id'].isin(\n",
    "            rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'user_id']),\n",
    "    'num_links_skipped'].sum() /\n",
    "    rate_data.loc[\n",
    "        ~rate_data['user_id'].isin(\n",
    "            rate_data.loc[rate_data['num_edit_sessions'] == rate_data['num_all_accepted'], 'user_id']),\n",
    "    'num_links_recommended'].sum(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ecc2d1",
   "metadata": {},
   "source": [
    "In both cases, the proportion of recommendations that actually get rejected is below the 30% threshold due to the proportion of skipped recommendations (7.6% across all sessions, 8.1% when excluding users who only have accepted recommendations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e696912",
   "metadata": {},
   "source": [
    "## Restricting it to >= 5 Edit Sessions\n",
    "\n",
    "Because most of the users who only accepted links had only a few sessions, what happens when it restrict it to those who had a least 5 sessions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e5e6ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rate_data.loc[(rate_data['num_edit_sessions'] == rate_data['num_all_accepted']) &\n",
    "                  (rate_data['num_edit_sessions'] >= 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a40ce",
   "metadata": {},
   "source": [
    "How many users made over 5 edit sessions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90d1de99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rate_data.loc[(rate_data['num_edit_sessions'] >= 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_data.loc[(rate_data['num_edit_sessions'] == rate_data['num_all_accepted']) &\n",
    "              (rate_data['num_edit_sessions'] >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b38d056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "     len(rate_data.loc[(rate_data['num_edit_sessions'] == rate_data['num_all_accepted']) &\n",
    "                  (rate_data['num_edit_sessions'] >= 5)]) /\n",
    "     len(rate_data), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2895ef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "     rate_data['num_all_accepted'].sum() /\n",
    "     rate_data['num_edit_sessions'].sum(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc7a6d",
   "metadata": {},
   "source": [
    "# Task Completion Rate\n",
    "\n",
    "Out of all users who start an Add a Link task, what proportion completes it?\n",
    "\n",
    "We define the start of a Add a Link task session as the impression of the \"machine suggestions\" mode in Visual Editors. Completion is defined as either clicking to save the edit at the edit summary dialog, as before, or confirming that they've skipped all suggestions. We've confirmed that if a user rejects all suggestions and clicks \"Submit\" on the edit summary, the event logged is the same as if they accepted any recommended links.\n",
    "\n",
    "Q: Should we limit this to users who signed up during the experiment, in order to filter out potentially experienced users who are just trying out the interface? What if more experienced users are more likely to complete the session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f829430",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_completion_query = '''\n",
    "WITH task_init AS (\n",
    "    -- select sessions where the user started\n",
    "    SELECT\n",
    "        coalesce(lsi.dt, lsi.meta.dt) AS event_dt,\n",
    "        lsi.homepage_pageview_token,\n",
    "        hpv.wiki,\n",
    "        hpv.event.user_id\n",
    "    FROM event.mediawiki_structured_task_article_link_suggestion_interaction AS lsi\n",
    "    JOIN event.homepagevisit AS hpv\n",
    "    ON lsi.homepage_pageview_token = hpv.event.homepage_pageview_token\n",
    "    WHERE {lsi_partition_statement}\n",
    "    AND {hpv_partition_statement}\n",
    "    AND hpv.wiki IN ({wiki_list})\n",
    "    AND ({known_user_id_expression})\n",
    "    AND lsi.active_interface = \"machinesuggestions_mode\"\n",
    "    AND lsi.action = \"impression\"\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) >= \"{start_ts}\" AND coalesce(lsi.dt, lsi.meta.dt) < \"{end_ts}\"\n",
    "),\n",
    "task_completion AS (\n",
    "    -- session where the user clicked \"save\"\n",
    "    SELECT\n",
    "        coalesce(lsi.dt, lsi.meta.dt) AS event_dt,\n",
    "        lsi.homepage_pageview_token,\n",
    "        1 AS saved_edit\n",
    "    FROM event.mediawiki_structured_task_article_link_suggestion_interaction AS lsi\n",
    "    JOIN task_init\n",
    "    ON lsi.homepage_pageview_token = task_init.homepage_pageview_token\n",
    "    WHERE {lsi_partition_statement}\n",
    "    AND (\n",
    "            (lsi.active_interface = \"editsummary_dialog\"\n",
    "             AND lsi.action = \"editsummary_save\")\n",
    "        OR\n",
    "            (lsi.active_interface = \"skipall_dialog\"\n",
    "             AND lsi.action = \"confirm_skip_all_suggestions\")\n",
    "        )\n",
    "    AND coalesce(lsi.dt, lsi.meta.dt) > task_init.event_dt\n",
    ")\n",
    "SELECT\n",
    "    task_init.wiki,\n",
    "    task_init.user_id,\n",
    "    1 AS started_task,\n",
    "    MAX(coalesce(task_completion.saved_edit, 0)) AS completed_task\n",
    "FROM task_init\n",
    "LEFT JOIN task_completion\n",
    "ON task_init.homepage_pageview_token = task_completion.homepage_pageview_token\n",
    "GROUP BY task_init.wiki, task_init.user_id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "564cd12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "task_completion_data = spark.run(\n",
    "    task_completion_query.format(\n",
    "        start_ts = exp_start_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        end_ts = exp_end_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis]),\n",
    "        known_user_id_expression = make_known_users_sql(known_users, 'wiki', 'hpv.event.user_id'),\n",
    "        lsi_partition_statement = make_partition_statement(exp_start_ts, exp_end_ts, prefix = 'lsi'),\n",
    "        hpv_partition_statement = make_partition_statement(exp_start_ts, exp_end_ts, prefix = 'hpv')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ae3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_completion_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b542691",
   "metadata": {},
   "source": [
    "Number of users who started a task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54a37ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task_completion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc688cc",
   "metadata": {},
   "source": [
    "Number of users who completed at least one task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3674e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task_completion_data.loc[task_completion_data['completed_task'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9383d9d1",
   "metadata": {},
   "source": [
    "Proportion of users who completed a task, out of those who started one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "209e5242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100 *\n",
    "     len(task_completion_data.loc[task_completion_data['completed_task'] == 1]) /\n",
    "     len(task_completion_data), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83092e2c",
   "metadata": {},
   "source": [
    "# Clarifying Questions\n",
    "\n",
    "What's the number of Add a Link edits in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6685451",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_link_tag_query = '''\n",
    "SELECT\n",
    "    `database` AS wiki,\n",
    "    COUNT(DISTINCT rev_id) AS num_edits\n",
    "    FROM event_sanitized.mediawiki_revision_tags_change\n",
    "    WHERE {partition_statement}\n",
    "    AND `database` IN ({wiki_list})\n",
    "    AND ({known_user_database_expression})\n",
    "    AND array_contains(tags, \"newcomer task add link\")\n",
    "    AND rev_timestamp >= \"{start_ts}\" AND rev_timestamp < \"{end_ts}\"\n",
    "    GROUP BY `database`\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4c89827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "tagged_edit_counts = spark.run(\n",
    "    add_link_tag_query.format(\n",
    "        start_ts = exp_start_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        end_ts = exp_end_ts.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "        wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis]),\n",
    "        known_user_database_expression = make_known_users_sql(known_users, '`database`', 'performer.user_id'),\n",
    "        partition_statement = make_partition_statement(exp_start_ts, exp_end_ts)\n",
    "    )\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_edit_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3829efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_edit_counts['num_edits'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
